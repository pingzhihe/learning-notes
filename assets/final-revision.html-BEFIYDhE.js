import{_ as a,c as e,a as t,o as n}from"./app-DsOgR8nk.js";const m={};function i(l,s){return n(),e("div",null,s[0]||(s[0]=[t('<p>Can the joint probability distribution described by any undirected probabilistic graphical model be expressed as a directed probabilistic graphical model? Explain why or why not?</p><ul><li>DPGM: capture asymmetric conditional independence based on the direction of edges. They are suitable for scenarios where causal or directional relationships are well-defined.</li><li>UPGM: capture symmetric conditional independence relationships. They are particularly suitable for situations where the direction of influence between variables is unclear or bidirectional.</li></ul><p>Why are vanishing gradients a more pressing concern for recurrent neural networks (RNNs) than for other neural architectures?</p><ul><li>RNNs handle data in sequences, passing information from one time step to the next. Gradients must flow back through many time steps during training, causing them to diminish exponentially. (BPTT)</li><li>RNNs use the same weights at each time step. This repetition leads to the multiplication of small gradient values repeatedly, making them vanish.</li><li>RNNs aim to learn relationships between distant elements in a sequence. Vanishing gradients make it difficult for the network to capture these long-range dependencies effectively.</li></ul><p>Solve</p><ul><li><strong>LTSM</strong> Long Short-Term Memory (LSTM) networks are a special type of Recurrent Neural Network (RNN) designed to effectively handle the vanishing gradient problem LSTMs use three types of gates to regulate the flow of information:</li></ul><p>Forget Gate:</p><p>Decides what information to discard from the cell state. Uses a sigmoid activation to output values between 0 and 1, effectively &quot;forgetting&quot; irrelevant information.</p><p>Input Gate:</p><p>Determines what new information to add to the cell state. Combines sigmoid and tanh activations to update the cell state with relevant data.</p><p>Output Gate:</p><p>Controls what information from the cell state is sent to the next hidden state. Ensures that only important information affects the network&#39;s output.</p><p>LSTMs have separate memory cells that store information over time, independent of the hidden states.</p><p>Why must theevidence becomputed when evaluating a Bayesian posterior , but when maximising the same posterior to find the max a posteriori (MAP) estimate, the evidence can be ignored/cancelled?</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>Œ∏</mi><mo>‚à£</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>D</mi><mo>‚à£</mo><mi>Œ∏</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>Œ∏</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex"> P(\\theta \\mid D) = \\frac{P(D \\mid \\theta) P(\\theta)}{P(D)} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">Œ∏</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">‚à£</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">‚à£</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">Œ∏</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">Œ∏</span><span class="mclose">)</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>Œ∏</mi><mo>‚à£</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(\\theta \\mid D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">Œ∏</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">‚à£</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span></span></span></span>:Probability of pa rameters ùúÉ given data ùê∑</li><li>Likelihood: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>D</mi><mo>‚à£</mo><mi>Œ∏</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(D \\mid \\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">‚à£</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">Œ∏</span><span class="mclose">)</span></span></span></span> Probability of data ùê∑ given parameters ùúÉ</li></ul><p>When you need the complete posterior distribution to calculate expectations, variances, or other statistical measures, the evidence is essential for accurate normalization.</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>Œ∏</mi><mtext>MAP</mtext></msub><mo>=</mo><mi>arg</mi><mo>‚Å°</mo><munder><mrow><mi>max</mi><mo>‚Å°</mo></mrow><mi>Œ∏</mi></munder><mrow><mo fence="true">(</mo><mi>P</mi><mo stretchy="false">(</mo><mi>D</mi><mo>‚à£</mo><mi>Œ∏</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>Œ∏</mi><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex"> \\theta_{\\text{MAP}} = \\arg\\max_{\\theta} \\left( P(D \\mid \\theta) P(\\theta) \\right) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">Œ∏</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">MAP</span></span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.5021em;vertical-align:-0.7521em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.4306em;"><span style="top:-2.3479em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">Œ∏</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.7521em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">‚à£</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">Œ∏</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">Œ∏</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></span></p><p>Do not need compute evidence</p>',19)]))}const r=a(m,[["render",i],["__file","final-revision.html.vue"]]),o=JSON.parse('{"path":"/stat-machine-learning/final-revision.html","title":"","lang":"en-US","frontmatter":{},"headers":[],"git":{"updatedTime":1730726714000,"contributors":[{"name":"pingzhihe","email":"pzh1760473545@gmail.com","commits":1,"url":"https://github.com/pingzhihe"}]},"filePathRelative":"stat-machine-learning/final-revision.md"}');export{r as comp,o as data};
