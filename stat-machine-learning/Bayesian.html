<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.18" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme')
      const systemDarkMode =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (userMode === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (userMode === 'dark' || systemDarkMode) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <style>
      :root {
        --content-width: 950px !important;     /* 调整内容区域最大宽度 */
      }
      
      /* 调整主要内容区域的宽度和边距 */
      .theme-default-content {
        max-width: var(--content-width);
        margin: 0 auto;
        padding: 2rem 2.5rem;
      }
    </style><title>Learning Notes</title><meta name="description" content="A note taking web site">
    <link rel="preload" href="/learning-notes/assets/style-CeqOocvs.css" as="style"><link rel="stylesheet" href="/learning-notes/assets/style-CeqOocvs.css">
    <link rel="modulepreload" href="/learning-notes/assets/app-DsOgR8nk.js"><link rel="modulepreload" href="/learning-notes/assets/Bayesian.html-DKqLsxtv.js">
    <link rel="prefetch" href="/learning-notes/assets/index.html-DiukWnyu.js" as="script"><link rel="prefetch" href="/learning-notes/assets/index.html-D7rYKWbh.js" as="script"><link rel="prefetch" href="/learning-notes/assets/revision-2.html-C1P0zbGW.js" as="script"><link rel="prefetch" href="/learning-notes/assets/revision-3.html-H5WRivyx.js" as="script"><link rel="prefetch" href="/learning-notes/assets/revision.html-j7uDJZWI.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Enums-Structs.html-B5x4Jgi6.js" as="script"><link rel="prefetch" href="/learning-notes/assets/index.html-CQ8rKHO-.js" as="script"><link rel="prefetch" href="/learning-notes/assets/basic.html-W8JFeAA1.js" as="script"><link rel="prefetch" href="/learning-notes/assets/pointers-2.html-CMWGu_On.js" as="script"><link rel="prefetch" href="/learning-notes/assets/pointers.html-BbZIyEFa.js" as="script"><link rel="prefetch" href="/learning-notes/assets/scope.html-CNsZl0YI.js" as="script"><link rel="prefetch" href="/learning-notes/assets/index.html-DncVXc6Z.js" as="script"><link rel="prefetch" href="/learning-notes/assets/lec.html-Cj2eamcj.js" as="script"><link rel="prefetch" href="/learning-notes/assets/revision.html-D9K8lSGg.js" as="script"><link rel="prefetch" href="/learning-notes/assets/index.html-Dj_jYuAM.js" as="script"><link rel="prefetch" href="/learning-notes/assets/commands.html-B2Nlgx6s.js" as="script"><link rel="prefetch" href="/learning-notes/assets/shortkeys.html-Bw1WT07S.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Basic.html-BQqgykgV.js" as="script"><link rel="prefetch" href="/learning-notes/assets/QAOA.html-CXcNTDWT.js" as="script"><link rel="prefetch" href="/learning-notes/assets/QFE.html-uZLoELzv.js" as="script"><link rel="prefetch" href="/learning-notes/assets/QFT.html-nC7_EMuw.js" as="script"><link rel="prefetch" href="/learning-notes/assets/index.html-CycaJi4z.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Teleportation.html-B5xiFHhT.js" as="script"><link rel="prefetch" href="/learning-notes/assets/shor's algotighm.html-CFkOzbw3.js" as="script"><link rel="prefetch" href="/learning-notes/assets/week11.html-BklFsnpI.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Closure.html-Da2fu2X7.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Emun.html-7GwBy-Ku.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Error-handle.html-Dn0oJ09B.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Fearless-concurrency.html-BMfS4r6X.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Life-time.html-O1LlmtO2.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Minigrep.html-CtAynLVu.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Num-type.html-DmsPYGp0.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Ownership.html-BQpY6Wb3.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Package-management.html-Btp44fEp.js" as="script"><link rel="prefetch" href="/learning-notes/assets/index.html-ColOM-Zh.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Smart-pointer.html-CGG3TVYS.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Struct.html-QbgWDSwd.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Test.html-18qFlW93.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Trait.html-BqHMDhMb.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Vector.html-BsWTR8k7.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Bayesian-inference.html-Cx9f9JxL.js" as="script"><link rel="prefetch" href="/learning-notes/assets/GMM-EM.html-jt6UK2iJ.js" as="script"><link rel="prefetch" href="/learning-notes/assets/Multi-Armed-Bandits.html-CCn_WnvB.js" as="script"><link rel="prefetch" href="/learning-notes/assets/index.html-BYPcUCdL.js" as="script"><link rel="prefetch" href="/learning-notes/assets/ann.html-_F-60DzV.js" as="script"><link rel="prefetch" href="/learning-notes/assets/cross-validation.html-BDU9hBjG.js" as="script"><link rel="prefetch" href="/learning-notes/assets/final-revision.html-BEFIYDhE.js" as="script"><link rel="prefetch" href="/learning-notes/assets/gmm-em.html-C-2OJUhS.js" as="script"><link rel="prefetch" href="/learning-notes/assets/revision-2.html-Cmf9Gy4X.js" as="script"><link rel="prefetch" href="/learning-notes/assets/revision.html-hB2XmEt4.js" as="script"><link rel="prefetch" href="/learning-notes/assets/svm.html-Div-Hb-t.js" as="script"><link rel="prefetch" href="/learning-notes/assets/week-12.html-DkRXhCon.js" as="script"><link rel="prefetch" href="/learning-notes/assets/404.html-uulsbaPi.js" as="script"><link rel="prefetch" href="/learning-notes/assets/setupDevtools-7MC2TMWH-BtqJD9t-.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon" vp-container><!--[--><header class="vp-navbar" vp-navbar><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/learning-notes/"><!----><span class="vp-site-name" aria-hidden="true">Learning Notes</span></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/learning-notes/" aria-label="Home"><!---->Home<!----></a></div><!--]--></nav><!--[--><!--]--><button type="button" class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><form class="search-box" role="search"><input type="search" placeholder="Search" autocomplete="off" spellcheck="false" value><!----></form></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/learning-notes/" aria-label="Home"><!---->Home<!----></a></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading collapsible" href="/learning-notes/guide/" aria-label="Guide"><!---->Guide<!----></a><ul style="display:none;" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/guide/shortkeys.html" aria-label="Shortkeys"><!---->Shortkeys<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/guide/commands.html" aria-label="Commands"><!---->Commands<!----></a><!----></li><!--]--></ul></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading collapsible" href="/learning-notes/CPP/" aria-label="Cpp"><!---->Cpp<!----></a><ul style="display:none;" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/CPP/basic.html" aria-label="Basic"><!---->Basic<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/CPP/scope.html" aria-label="Scope, Duration, and Linkage"><!---->Scope, Duration, and Linkage<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/CPP/pointers.html" aria-label="Pointers(1)"><!---->Pointers(1)<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/CPP/pointers-2.html" aria-label="Pointers(2)"><!---->Pointers(2)<!----></a><!----></li><!--]--></ul></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading collapsible" href="/learning-notes/rust-learning/" aria-label="Rust Learning"><!---->Rust Learning<!----></a><ul style="display:none;" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/rust-learning/Num-type.html" aria-label="1.Number Types"><!---->1.Number Types<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/rust-learning/Ownership.html" aria-label="2.Ownership"><!---->2.Ownership<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/rust-learning/Struct.html" aria-label="3.Struct"><!---->3.Struct<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/rust-learning/Emun.html" aria-label="4.Enum"><!---->4.Enum<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/rust-learning/Package-management.html" aria-label="5.Package-management"><!---->5.Package-management<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/rust-learning/Vector.html" aria-label="6.Vector"><!---->6.Vector<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/rust-learning/Error-handle.html" aria-label="7.Error handle"><!---->7.Error handle<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/rust-learning/Trait.html" aria-label="8.Trait  泛型"><!---->8.Trait  泛型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/rust-learning/Life-time.html" aria-label="9.Life time"><!---->9.Life time<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/rust-learning/Test.html" aria-label="10.Test"><!---->10.Test<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/rust-learning/Minigrep.html" aria-label="11.Minigrep"><!---->11.Minigrep<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/rust-learning/Closure.html" aria-label="12.Closure 闭包"><!---->12.Closure 闭包<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/rust-learning/Smart-pointer.html" aria-label="13.Smart pointer 智能指针"><!---->13.Smart pointer 智能指针<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/rust-learning/Fearless-concurrency.html" aria-label="14.Fearless concurrency 无畏并发"><!---->14.Fearless concurrency 无畏并发<!----></a><!----></li><!--]--></ul></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading collapsible" href="/learning-notes/quantum-computing/" aria-label="Quantum Computing"><!---->Quantum Computing<!----></a><ul style="display:none;" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/quantum-computing/Basic.html" aria-label="Basic computing and quantum computing Theory"><!---->Basic computing and quantum computing Theory<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/quantum-computing/Teleportation.html" aria-label="Teleportation"><!---->Teleportation<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/quantum-computing/QFT.html" aria-label="QKD and QFT"><!---->QKD and QFT<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/quantum-computing/QFE.html" aria-label="QFE and Shor&#39;s algorithm"><!---->QFE and Shor&#39;s algorithm<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/quantum-computing/QAOA.html" aria-label="QAOA"><!---->QAOA<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/quantum-computing/shor&#39;s%20algotighm.html" aria-label="Quantum algorithms"><!---->Quantum algorithms<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/quantum-computing/week11.html" aria-label="Week 11"><!---->Week 11<!----></a><!----></li><!--]--></ul></li><li><a class="route-link route-link-active auto-link vp-sidebar-item vp-sidebar-heading active collapsible" href="/learning-notes/stat-machine-learning/" aria-label="Statical Machine Learning"><!---->Statical Machine Learning<!----></a><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link route-link-active auto-link vp-sidebar-item active" href="/learning-notes/stat-machine-learning/Bayesian.html" aria-label="Bayesian Linear Regression"><!---->Bayesian Linear Regression<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/stat-machine-learning/revision.html" aria-label="Linear regression and logistic regresion"><!---->Linear regression and logistic regresion<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/stat-machine-learning/revision-2.html" aria-label="Bais"><!---->Bais<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/stat-machine-learning/svm.html" aria-label="SVM, Kernel Methods"><!---->SVM, Kernel Methods<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/stat-machine-learning/ann.html" aria-label="Precepction and Artificial Neural Network"><!---->Precepction and Artificial Neural Network<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/stat-machine-learning/cross-validation.html" aria-label="Cross validation, experts learning, MAB"><!---->Cross validation, experts learning, MAB<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/stat-machine-learning/Bayesian-inference.html" aria-label="Bayesian inference"><!---->Bayesian inference<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/stat-machine-learning/GMM-EM.html" aria-label="GMM-EM"><!---->GMM-EM<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/stat-machine-learning/final-revision.html" aria-label="final"><!---->final<!----></a><!----></li><!--]--></ul></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading collapsible" href="/learning-notes/SPM/" aria-label="Software Project Management"><!---->Software Project Management<!----></a><ul style="display:none;" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/SPM/lec.html" aria-label="Lecture"><!---->Lecture<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/SPM/revision.html" aria-label="Revision"><!---->Revision<!----></a><!----></li><!--]--></ul></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading collapsible" href="/learning-notes/AI-planning/" aria-label="AI-planning"><!---->AI-planning<!----></a><ul style="display:none;" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/AI-planning/revision.html" aria-label="Classical planning"><!---->Classical planning<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/AI-planning/revision-2.html" aria-label="MDP and reinforcement learning"><!---->MDP and reinforcement learning<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/learning-notes/AI-planning/revision-3.html" aria-label="Game theory and final recap"><!---->Game theory and final recap<!----></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div class="theme-default-content" vp-content><!--[--><!--]--><div><h2 id="the-bayesian-view" tabindex="-1"><a class="header-anchor" href="#the-bayesian-view"><span>The Bayesian view</span></a></h2><p><strong>Retain and model all unknowns (e.g., uncertainty over parameters) and use this information when making inferences.</strong></p><p>贝叶斯学派和频率学派在统计推断方面有一些根本的区别</p><ol><li>参数的本质</li></ol><ul><li>频率学派: 认为参数是固定但未知的常数。</li><li>贝叶斯学派: 将参数视为随机变量，有其自身的概率分布。</li></ul><ol start="2"><li>概率的定义:</li></ol><ul><li>频率学派: 概率被定义为长期频率。</li><li>贝叶斯学派: 概率表示信念的程度或合理期望。</li></ul><ol start="3"><li>推断方法:</li></ol><ul><li>频率学派: 基于假设的重复采样。</li><li>贝叶斯学派: 使用信度区间（也称后验区间）。</li></ul><ol start="4"><li>小样本推断:</li></ol><ul><li>频率学派: 在小样本情况下可能表现不佳。</li><li>贝叶斯学派: 可以更好地处理小样本情况，特别是当有合理的先验时。</li></ul><p>5.结果的解释:</p><ul><li>频率学派: &quot;如果我们重复这个实验很多次，95%的置信区间会包含真实参数。&quot;</li><li>贝叶斯学派: &quot;基于当前数据和先验信息，真实参数有95%的概率落在这个区间内。&quot;</li></ul><p>recap: 在频率统计中认为数据是服从某种概率分布的，我们需要找到某个分布的参数。而且随着样本的批次越来越多， 估计参数会趋近于实际参数。在贝叶斯统计中认为<strong>参数</strong>也是服从某些分布的。在没有任何数据的支持下的分布被称为<strong>先验分布</strong>。贝叶斯用数据的<strong>似然函数</strong>来更新先验分布，从而得到参数的<strong>后验分布</strong>。</p><p><strong>So, What is Likelihood? That is a question confues me for a very loooooong time!</strong> I found a set of cool explanations!<br><a href="https://stats.stackexchange.com/questions/2641/what-is-the-difference-between-likelihood-and-probability" target="_blank" rel="noopener noreferrer">What is the difference between &quot;likelihood&quot; and &quot;probability&quot;?</a></p><p>似然函数告诉我们，在给定的数据下，模型的不同参数值有多大可能性是正确的。高似然值表示数据强烈支持某个参数值，低似然值则表示数据不太支持该参数值。<br> Likelihood is a measure of the extent to which a sample provides support for particular values of a parameter in a parametric model.</p><p><strong>Could we reason over all parameters that are consistent with the data?</strong></p><p>首先，贝叶斯观点提出了一个重要的问题：我们能否考虑所有与数据一致的参数? Consistent: 与数据一致的参数 指的是那些在模型中能够以非零概率生成我们观测到的数据的参数值。</p><ul><li>weights with a better fit to the training data should be more probable than others.</li><li>make predictions with all these weights, scaled by their probability.</li></ul><h3 id="advantage-of-bayesian" tabindex="-1"><a class="header-anchor" href="#advantage-of-bayesian"><span>Advantage of Bayesian</span></a></h3><ul><li>Many <strong>reasonable</strong> solutions to objective<br> 多种合理的解决方案</li></ul><p>More robust predictions</p><ul><li><p>less sensitive to overfitting, particularly with small training sets<br> 防止过拟合，特别是很小的数据集下</p></li><li><p>Can give rise to more expressive model class (Bayesian logistic regression becomes <strong>non-linear</strong>!)</p></li></ul><h3 id="mini-summary" tabindex="-1"><a class="header-anchor" href="#mini-summary"><span>Mini summary</span></a></h3><ul><li>Frequentist’s central preference of point estimates don’t capture uncertainty</li><li>Bayesian view is to quantify belief in prior, update it to posterior using observations<br> 贝叶斯观点是量化对先验的信念，并通过观测更新为后验信念。</li></ul><h3 id="bayesian-linear-regression" tabindex="-1"><a class="header-anchor" href="#bayesian-linear-regression"><span>Bayesian Linear Regression</span></a></h3><p>Probabilistic formulation of linear regression:</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>∼</mo><mtext>Normal</mtext><mo stretchy="false">(</mo><msup><mi mathvariant="bold">x</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi mathvariant="bold">w</mi><mo separator="true">,</mo><msup><mi>σ</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex"> y\sim \text{Normal}(\mathbf{x}&#39;\mathbf{w}, \sigma^2) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Normal</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord mathbf" style="margin-right:0.01597em;">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>Prior distribution of weight w:</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">w</mi><mo>∼</mo><mtext>Normal</mtext><mo stretchy="false">(</mo><mn mathvariant="bold">0</mn><mo separator="true">,</mo><msup><mi>γ</mi><mn>2</mn></msup><msub><mi mathvariant="bold">I</mi><mi>D</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex"> \mathbf{w} \sim \text{Normal}(\mathbf{0}, \gamma^2\mathbf{I}_D) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">w</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Normal</span></span><span class="mopen">(</span><span class="mord mathbf">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathbf">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>Bayesian rule:</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi mathvariant="bold">w</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">X</mi><mo separator="true">,</mo><mi mathvariant="bold">y</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>p</mi><mo stretchy="false">(</mo><mi mathvariant="bold">y</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">X</mi><mo separator="true">,</mo><mi mathvariant="bold">w</mi><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><mi mathvariant="bold">w</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><mo stretchy="false">(</mo><mi mathvariant="bold">y</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">X</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex"> p(\mathbf{w}|\mathbf{X}, \mathbf{y}) = \frac{p(\mathbf{y}|\mathbf{X}, \mathbf{w})p(\mathbf{w})}{p(\mathbf{y}|\mathbf{X})} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathbf" style="margin-right:0.01597em;">w</span><span class="mord">∣</span><span class="mord mathbf">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathbf" style="margin-right:0.01597em;">y</span><span class="mord">∣</span><span class="mord mathbf">X</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathbf" style="margin-right:0.01597em;">y</span><span class="mord">∣</span><span class="mord mathbf">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">w</span><span class="mclose">)</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathbf" style="margin-right:0.01597em;">w</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>Calculate the posterior distribution of weight w. 用于计算权重w的后验概率</p><h3 id="bayesian-linear-regression-cont" tabindex="-1"><a class="header-anchor" href="#bayesian-linear-regression-cont"><span>Bayesian Linear Regression (cont.)</span></a></h3><p><strong>conjugate prior</strong>: when product of likelihood x prior results in the same distribution as the prior<br> 共轭先验：当似然函数与先验的乘积结果与先验属于相同分布时。</p><h4 id="sequential-bayesian-updating" tabindex="-1"><a class="header-anchor" href="#sequential-bayesian-updating"><span><strong>Sequential Bayesian Updating</strong></span></a></h4><ul><li><p>Can formulate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi mathvariant="bold">w</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">X</mi><mo separator="true">,</mo><mi mathvariant="bold">y</mi><mo separator="true">,</mo><msup><mi>σ</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\mathbf{w}|\mathbf{X}, \mathbf{y}, \sigma^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathbf" style="margin-right:0.01597em;">w</span><span class="mord">∣</span><span class="mord mathbf">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> in closed form</p></li><li><p>What happens as we see more and more data?</p><ol><li>Start from prior <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>w</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(w)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mclose">)</span></span></span></span>     从先验分布开始</li><li>See new labelled datapoint     看到新的数据点</li><li>Compite Posterior <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi mathvariant="bold">w</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">X</mi><mo separator="true">,</mo><mi mathvariant="bold">y</mi><mo separator="true">,</mo><msup><mi>σ</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\mathbf{w}|\mathbf{X}, \mathbf{y}, \sigma^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathbf" style="margin-right:0.01597em;">w</span><span class="mord">∣</span><span class="mord mathbf">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>     计算后验分布</li><li>The <em>posterior now takes role of prior</em>     后验分布现在扮演先验分布的角色 Repeat from step 2</li></ol></li><li><p>Key features:</p><ul><li>Initially know little, many regression lines licensed 最初了解甚少，许多回归线被认可。</li><li>Likelihood constrains possible weights such that regression is close to point Likelihood限制了可能的权重，使得回归接近目标。</li><li>Posterior becomes more refined/peaked as more data introduced 后验概率随着数据的增加变得更加精细</li><li>Approaches a point mass 接近点质量</li></ul></li></ul><p>MAP 是 MLE 的一个扩展，它不仅考虑数据的似然，还考虑了参数的先验分布</p><ul><li>结合了似然函数和参数的先验分布</li><li>可以看作是频率学派和贝叶斯学派的一个折中</li></ul><p>MAP estimation can therefore be seen as a regularization of maximum likelihood estimation. <a href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation" target="_blank" rel="noopener noreferrer">wikipedia-MAP</a><br> MAP估计可以视为最大似然估计的一种正则化。</p><h3 id="caveats" tabindex="-1"><a class="header-anchor" href="#caveats"><span>Caveats</span></a></h3><p><strong>Assumptions</strong></p><ul><li>known data noise parameter, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sigma^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></li><li>data was drawn from the model distribution</li></ul><h3 id="mini-summary-1" tabindex="-1"><a class="header-anchor" href="#mini-summary-1"><span>Mini Summary</span></a></h3><p><strong>Uncertainty not captured by point estimates (MLE, MAP)</strong><strong>Bayesian approach preserves uncertainty</strong></p><ul><li>care about <em>predictions</em> NOT <em>parameters</em></li><li>choose prior over parameters, then model posterior</li></ul><p><strong>New concepts:</strong></p><ul><li>sequential Bayesian updating</li><li>conjugate prior (Normal-Normal)</li></ul><p><strong>Using posterior for Bayesian predictions on test</strong></p><h2 id="bayesian-classification" tabindex="-1"><a class="header-anchor" href="#bayesian-classification"><span>Bayesian classification</span></a></h2><p><strong>Bayesian ideas in discrete settings</strong></p><ul><li>Beta-Binomial conjugacy</li></ul><p><strong>Bayesian logistic regression</strong></p><ul><li>Non-conjugacy</li><li>Pointer: Laplace approximation</li></ul><h3 id="beta-binomial-conjugate" tabindex="-1"><a class="header-anchor" href="#beta-binomial-conjugate"><span>Beta-Binomial conjugate</span></a></h3><p>Consider n coin tosses, of which k were heads, let <strong>p(head) = q</strong> from a <strong>single toss (Bernoulli dist)</strong><br> The inference question is the coin baised, ie., is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo>≈</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">q \approx 0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6776em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.5</span></span></span></span></p><ul><li>Likelihood function for coin toss:</li></ul><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>k</mi><mi mathvariant="normal">∣</mi><mi>n</mi><mo separator="true">,</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mi>n</mi><mi>k</mi></mfrac><mo fence="true">)</mo></mrow><msup><mi>q</mi><mi>k</mi></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>q</mi><msup><mo stretchy="false">)</mo><mrow><mi>n</mi><mo>−</mo><mi>k</mi></mrow></msup></mrow><annotation encoding="application/x-tex"> p(k|n,q) = \binom{n}{k}q^k(1-q)^{n-k} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord">∣</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="mord"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1076em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1491em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li>Prior:</li></ul><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>Beta</mtext><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">;</mo><mi>α</mi><mo separator="true">,</mo><mi>β</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>γ</mi><mo stretchy="false">(</mo><mi>α</mi><mo>+</mo><mi>β</mi><mo stretchy="false">)</mo></mrow><mrow><mi>γ</mi><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo><mi>γ</mi><mo stretchy="false">(</mo><mi>β</mi><mo stretchy="false">)</mo></mrow></mfrac><msup><mi>q</mi><mrow><mi>α</mi><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>q</mi><msup><mo stretchy="false">)</mo><mrow><mi>β</mi><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex"> p(q) = \text{Beta}(q; \alpha, \beta) = \frac{\gamma(\alpha + \beta)}{\gamma(\alpha)\gamma(\beta)}q^{\alpha-1}(1-q)^{\beta-1} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Beta</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1491em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05278em;">β</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li>Bayesian posterior:</li></ul><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>q</mi><mi mathvariant="normal">∣</mi><mi>k</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo><mo>∝</mo><mi>p</mi><mo stretchy="false">(</mo><mi>k</mi><mi mathvariant="normal">∣</mi><mi>n</mi><mo separator="true">,</mo><mi>q</mi><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex"> p(q|k,n) \propto p(k|n,q)p(q) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord">∣</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose">)</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose">)</span></span></span></span></span></p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo>∝</mo><msup><mi>q</mi><mi>k</mi></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>q</mi><msup><mo stretchy="false">)</mo><mrow><mi>n</mi><mo>−</mo><mi>k</mi></mrow></msup><msup><mi>q</mi><mrow><mi>α</mi><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>q</mi><msup><mo stretchy="false">)</mo><mrow><mi>β</mi><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex"> \propto q^k(1-q)^{n-k}q^{\alpha-1}(1-q)^{\beta-1} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1491em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1491em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1491em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05278em;">β</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span></span></p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo>=</mo><msup><mi>q</mi><mrow><mi>k</mi><mo>+</mo><mi>α</mi><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>q</mi><msup><mo stretchy="false">)</mo><mrow><mi>n</mi><mo>−</mo><mi>k</mi><mo>+</mo><mi>β</mi><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex"> = q^{k+\alpha-1}(1-q)^{n-k+\beta-1} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1491em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1491em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.05278em;">β</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span></span></p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo>∝</mo><mtext>Beta</mtext><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">;</mo><mi>k</mi><mo>+</mo><mi>α</mi><mo separator="true">,</mo><mi>n</mi><mo>−</mo><mi>k</mi><mo>+</mo><mi>β</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex"> \propto \text{Beta}(q; k+\alpha, n-k+\beta) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Beta</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mclose">)</span></span></span></span></span></p><p><img src="/learning-notes/assets/image-D_dkgy3d.png" alt="alt text" title="width=200px"></p><h3 id="bayesian-logistic-regression" tabindex="-1"><a class="header-anchor" href="#bayesian-logistic-regression"><span>Bayesian Logistic Regression</span></a></h3><p>Discriminative classifier, which conditions on inputs. How can we do Bayesian inference in this setting?</p><p>Model is discriminative, with parameters defined using logistic sigmoid so:</p><ul><li>need prior over w, not q</li><li>no known conjugate prior !, thus use a Gaussian prior</li></ul><p>Approach to inference: <strong>Monte Carlo sampling</strong></p><h2 id="pgm-representation" tabindex="-1"><a class="header-anchor" href="#pgm-representation"><span>PGM Representation</span></a></h2><p><strong>(Directed) probabilistic graphical models</strong></p><ul><li>Motivations: applications, unifies algorithms</li><li>Motivation: ideal tool for Bayesians</li><li>Independence lowers computational/model complexity <ul><li>Conditional independence</li></ul></li></ul><h3 id="probabilistic-graphical-models" tabindex="-1"><a class="header-anchor" href="#probabilistic-graphical-models"><span>Probabilistic Graphical Models</span></a></h3><p><strong>Marriage of graph theory and probability theory. Tool of choice for Bayesian statistical learning.</strong><br> 概率图模型结合了图论和概率论的思想，是贝叶斯统计学习的一个核心工具。</p><p>独立性假设的好处：通过假设某些随机变量之间是独立的，可以将联合分布分解为多个较小的分布，从而简化计算。这使得模型更加紧凑，减少了计算复杂度。<br> 对于任意的随机变量顺序，联合分布可以通过条件概率进行分解。</p><h3 id="有向概率图模型-d-pgm" tabindex="-1"><a class="header-anchor" href="#有向概率图模型-d-pgm"><span>有向概率图模型（D-PGM）</span></a></h3><h3 id="无向概率图模型-u-pgm" tabindex="-1"><a class="header-anchor" href="#无向概率图模型-u-pgm"><span>无向概率图模型（U-PGM）</span></a></h3></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: pzh1760473545@gmail.com">pingzhihe</span><!----><!--]--><!--]--></span></div></div></footer><nav class="vp-page-nav" aria-label="page navigation"><!----><a class="route-link auto-link next" href="/learning-notes/stat-machine-learning/revision.html" aria-label="Linear regression and logistic regresion"><div class="hint">Next <span class="arrow right"></span></div><div class="link"><span>Linear regression and logistic regresion</span></div></a></nav><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/learning-notes/assets/app-DsOgR8nk.js" defer></script>
  </body>
</html>
